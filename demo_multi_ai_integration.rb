#!/usr/bin/env ruby
# frozen_string_literal: true

# Demo script for RailsPlan Multi-AI CLI Integration
# This script demonstrates the new multi-AI provider capabilities

$LOAD_PATH.unshift(File.expand_path('lib', __dir__))

# Minimal setup for demo
module RailsPlan
  class Error < StandardError; end
  
  def self.logger
    @logger ||= Logger.new(STDOUT).tap { |l| l.level = Logger::INFO }
  end
end

require 'logger'
require 'railsplan/ai_config'
require 'railsplan/ai'
require 'tempfile'
require 'fileutils'

puts "üöÄ RailsPlan Multi-AI CLI Integration Demo"
puts "=" * 50

# Create a temporary config for the demo
temp_dir = Dir.mktmpdir("railsplan_demo")
config_path = File.join(temp_dir, "ai.yml")

# Demo configuration with multiple providers
demo_config = <<~YAML
  # Default provider configuration
  provider: openai
  model: gpt-4o
  openai_api_key: demo_openai_key_123
  claude_api_key: demo_claude_key_456  
  gemini_api_key: demo_gemini_key_789
  
  # Provider profiles for different scenarios
  profiles:
    development:
      provider: openai
      model: gpt-4o-mini
      openai_api_key: demo_dev_key
    production:
      provider: claude
      model: claude-3-5-sonnet-20241022
      claude_api_key: demo_prod_key
    experimental:
      provider: gemini
      model: gemini-1.5-pro
      gemini_api_key: demo_exp_key
    local:
      provider: cursor
      # Cursor doesn't require API keys
YAML

File.write(config_path, demo_config)

# Override the config path for demo
original_path = RailsPlan::AIConfig::DEFAULT_CONFIG_PATH
RailsPlan::AIConfig.send(:remove_const, :DEFAULT_CONFIG_PATH)
RailsPlan::AIConfig.const_set(:DEFAULT_CONFIG_PATH, config_path)

begin
  puts "\n1. üîß Configuration Management"
  puts "   Created demo configuration with multiple providers"
  
  # Show default configuration
  config = RailsPlan::AIConfig.new
  puts "   Default provider: #{config.provider}"
  puts "   Default model: #{config.model}"
  
  # Show profile configurations  
  profiles = ['development', 'production', 'experimental', 'local']
  profiles.each do |profile|
    profile_config = RailsPlan::AIConfig.new(profile: profile)
    puts "   #{profile} profile: #{profile_config.provider} (#{profile_config.model})"
  end
  
  puts "\n2. ü§ñ AI Provider Interface"
  puts "   Available providers: #{RailsPlan::AI.available_providers.join(', ')}"
  
  # Show which providers would be available (simulated)
  RailsPlan::AI.available_providers.each do |provider|
    config = RailsPlan::AIConfig.new(provider: provider)
    status = config.configured? ? "‚úÖ Configured" : "‚ùå Not configured"
    puts "   #{provider}: #{status}"
  end
  
  puts "\n3. üìù Unified AI Interface Examples"
  
  # Example prompts for different formats
  examples = [
    {
      provider: :openai,
      prompt: "Generate a Ruby User model with email validation",
      format: :ruby,
      description: "Code generation with OpenAI"
    },
    {
      provider: :claude,
      prompt: "Create a JSON API response for user data",
      format: :json,
      description: "JSON generation with Claude"
    },
    {
      provider: :gemini,
      prompt: "Explain Rails conventions in markdown",
      format: :markdown,
      description: "Documentation with Gemini"
    },
    {
      provider: :cursor,
      prompt: "Generate an HTML partial for user profile",
      format: :html_partial,
      description: "UI generation with Cursor"
    }
  ]
  
  examples.each_with_index do |example, index|
    puts "\n   Example #{index + 1}: #{example[:description]}"
    puts "   Provider: #{example[:provider]}"
    puts "   Format: #{example[:format]}"
    puts "   Prompt: \"#{example[:prompt]}\""
    
    # Show what the API call would look like
    puts "   API Call:"
    puts "   RailsPlan::AI.call("
    puts "     provider: :#{example[:provider]},"
    puts "     prompt: \"#{example[:prompt]}\","
    puts "     format: :#{example[:format]},"
    puts "     context: {...},"
    puts "     creative: false"
    puts "   )"
  end
  
  puts "\n4. üîÄ Provider Fallback Logic"
  puts "   Automatic fallback when primary provider fails:"
  
  fallback_examples = [
    { primary: :openai, fallback: :claude },
    { primary: :claude, fallback: :openai },
    { primary: :gemini, fallback: :openai },
    { primary: :cursor, fallback: :openai }
  ]
  
  fallback_examples.each do |example|
    puts "   #{example[:primary]} ‚Üí #{example[:fallback]} (if #{example[:primary]} fails)"
  end
  
  puts "\n5. üìä Enhanced Logging & Monitoring"
  
  # Create demo .railsplan directory
  log_dir = File.join(temp_dir, ".railsplan")
  FileUtils.mkdir_p(log_dir)
  
  # Simulate logging
  original_dir = Dir.pwd
  Dir.chdir(temp_dir)
  
  demo_metadata = {
    timestamp: Time.now.strftime("%Y-%m-%dT%H:%M:%SZ"),
    provider: :openai,
    model: "gpt-4o",
    format: :ruby,
    success: true,
    prompt_size: 150,
    tokens_used: 75,
    cost_estimate: 0.003
  }
  
  # Log a demo interaction
  RailsPlan::AI.send(:log_interaction, 
    "Generate a User model with validations", 
    "class User < ApplicationRecord\n  validates :email, presence: true\nend", 
    demo_metadata
  )
  
  RailsPlan::AI.send(:log_usage, demo_metadata)
  
  puts "   ‚úÖ Prompt logging: .railsplan/prompts.log"
  puts "   ‚úÖ Usage tracking: .railsplan/ai_usage.log"
  puts "   ‚úÖ Cost estimation: $#{demo_metadata[:cost_estimate]}"
  puts "   ‚úÖ Token counting: #{demo_metadata[:tokens_used]} tokens"
  
  # Show log contents
  if File.exist?(File.join(log_dir, "prompts.log"))
    puts "\n   Sample prompt log entry:"
    log_content = File.read(File.join(log_dir, "prompts.log")).strip
    puts "   #{log_content[0..100]}..." if log_content.length > 100
  end
  
  puts "\n6. üéØ CLI Command Examples"
  puts "   New and enhanced commands:"
  
  cli_examples = [
    "railsplan chat                                    # Interactive AI testing",
    "railsplan chat \"Explain Ruby blocks\"             # Quick AI query",
    "railsplan generate \"User model\" --provider=claude # Generate with specific provider",
    "railsplan generate \"API endpoint\" --format=json  # Generate in specific format",
    "railsplan explain app/models/user.rb --provider=gemini # Code explanation",
    "railsplan doctor --fix                           # Enhanced diagnostics with AI",
    "railsplan chat --provider=cursor --format=html   # Test Cursor integration"
  ]
  
  cli_examples.each do |example|
    puts "   #{example}"
  end
  
  puts "\n7. ‚öôÔ∏è  Configuration Options"
  puts "   Multiple ways to configure providers:"
  
  config_examples = [
    "~/.railsplan/ai.yml           # Global configuration",
    ".railsplan/ai.yml             # Project-specific config",
    "OPENAI_API_KEY=...            # Environment variables",
    "ANTHROPIC_API_KEY=...         # Provider-specific env vars",
    "GOOGLE_API_KEY=...            # Gemini configuration",
    "--provider=claude             # CLI override"
  ]
  
  config_examples.each do |example|
    puts "   #{example}"
  end
  
  Dir.chdir(original_dir)
  
rescue => e
  puts "   ‚ùå Demo error: #{e.message}"
ensure
  # Cleanup
  FileUtils.rm_rf(temp_dir)
  
  # Restore original config path
  RailsPlan::AIConfig.send(:remove_const, :DEFAULT_CONFIG_PATH)
  RailsPlan::AIConfig.const_set(:DEFAULT_CONFIG_PATH, original_path)
end

puts "\n" + "=" * 50
puts "‚ú® Multi-AI Integration Successfully Implemented!"
puts ""
puts "üéØ Key Features:"
puts "   ‚Ä¢ Unified AI interface supporting 4 providers"
puts "   ‚Ä¢ Automatic fallback and retry logic"
puts "   ‚Ä¢ Format validation (JSON, Ruby, Markdown, HTML)"
puts "   ‚Ä¢ Enhanced configuration with profiles"
puts "   ‚Ä¢ Comprehensive logging and cost tracking"
puts "   ‚Ä¢ Interactive chat command for testing"
puts "   ‚Ä¢ Provider switching via CLI flags"
puts ""
puts "üöÄ Ready for production use!"